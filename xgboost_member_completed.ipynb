{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "452ca550",
   "metadata": {},
   "source": [
    "# ML Model with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc5cea37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c76f136",
   "metadata": {},
   "source": [
    "## Import the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e4b0891",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/features_member_completed.csv', index_col=0)\n",
    "labels = pd.read_csv('data/labels_member_completed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "850c5b5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63288, 17), (63288, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ea0ae3d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>member_since_days</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>bogo</th>\n",
       "      <th>discount</th>\n",
       "      <th>informational</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.252880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.341196</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.043335</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.464619</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530120</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>120</td>\n",
       "      <td>0.421832</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63283</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>0.505760</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63284</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>0.077894</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63285</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>0.133297</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63286</th>\n",
       "      <td>0.759036</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>0.045529</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63287</th>\n",
       "      <td>0.024096</td>\n",
       "      <td>0.155556</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>168</td>\n",
       "      <td>0.072957</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63288 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age    income  reward  difficulty  duration  member_since_days  \\\n",
       "0      0.180723  0.466667       5           5       120           0.252880   \n",
       "1      0.072289  0.333333       5           5       120           0.341196   \n",
       "2      0.445783  0.488889       5           5       120           0.043335   \n",
       "3      0.433735  0.766667       5           5       120           0.464619   \n",
       "4      0.530120  0.566667       5           5       120           0.421832   \n",
       "...         ...       ...     ...         ...       ...                ...   \n",
       "63283  0.438476  0.393389      10          10       168           0.505760   \n",
       "63284  0.438476  0.393389      10          10       168           0.077894   \n",
       "63285  0.438476  0.393389      10          10       168           0.133297   \n",
       "63286  0.759036  0.388889      10          10       168           0.045529   \n",
       "63287  0.024096  0.155556      10          10       168           0.072957   \n",
       "\n",
       "       email  mobile  social  web  F  M  O  U  bogo  discount  informational  \n",
       "0          1       1       1    1  0  1  0  0     1         0              0  \n",
       "1          1       1       1    1  1  0  0  0     1         0              0  \n",
       "2          1       1       1    1  1  0  0  0     1         0              0  \n",
       "3          1       1       1    1  0  1  0  0     1         0              0  \n",
       "4          1       1       1    1  1  0  0  0     1         0              0  \n",
       "...      ...     ...     ...  ... .. .. .. ..   ...       ...            ...  \n",
       "63283      1       1       1    0  0  0  0  1     1         0              0  \n",
       "63284      1       1       1    0  0  0  0  1     1         0              0  \n",
       "63285      1       1       1    0  0  0  0  1     1         0              0  \n",
       "63286      1       1       1    0  1  0  0  0     1         0              0  \n",
       "63287      1       1       1    0  0  1  0  0     1         0              0  \n",
       "\n",
       "[63288 rows x 17 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee3f646",
   "metadata": {},
   "source": [
    "## Create Training, Validation and Testdata\n",
    "\n",
    "The loaded data is already preprocessed, there are no further data cleaning steps necessary. However, we do need to split the rows in the dataset up into train, test and validation sets.\n",
    "To avoid overfitting I split the train data additional in validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d67a703",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f2c560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d14081c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b844ce05",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "954caa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfae1cd",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions\n",
    "In addition to the modules above, we need to import the various bits of SageMaker that we will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "653768f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe6778c",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the created files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38384ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_completed'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861f4cc1",
   "metadata": {},
   "source": [
    "## Create Sagemaker Estimator and Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "41d09e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a SageMaker estimator using the container location determined in the previous cell.\n",
    "#       It is recommended that you use a single training instance of type ml.m4.xlarge. It is also\n",
    "#       recommended that you use 's3://{}/{}/output'.format(session.default_bucket(), prefix) as the\n",
    "#       output path.\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "# TODO: Set the XGBoost hyperparameters in the xgb object. Don't forget that in this case we have a binary\n",
    "#       label so we should be using the 'binary:logistic' objective.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10, \n",
    "                        num_round=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726dc25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f33fa8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61cc5a79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-05 08:22:05 Starting - Starting the training job...\n",
      "2021-10-05 08:22:07 Starting - Launching requested ML instancesProfilerReport-1633422125: InProgress\n",
      "...\n",
      "2021-10-05 08:22:54 Starting - Preparing the instances for training.........\n",
      "2021-10-05 08:24:34 Downloading - Downloading input data...\n",
      "2021-10-05 08:24:58 Training - Downloading the training image...\n",
      "2021-10-05 08:25:34 Uploading - Uploading generated training model\n",
      "2021-10-05 08:25:34 Completed - Training job completed\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:25:21:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:25:21:INFO] File size need to be processed in the node: 3.62mb. Available memory size in the node: 8375.8mb\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:25:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:25:21] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[08:25:21] 28409x17 matrix with 482953 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:25:21:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[08:25:21] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[08:25:21] 13993x17 matrix with 237881 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.281882#011validation-error:0.287144\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.276638#011validation-error:0.279568\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.273434#011validation-error:0.274852\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.271534#011validation-error:0.274066\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.268788#011validation-error:0.271064\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.268823#011validation-error:0.270492\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.268964#011validation-error:0.269277\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.269281#011validation-error:0.270492\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 54 extra nodes, 2 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.268119#011validation-error:0.270707\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.268471#011validation-error:0.270707\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.267274#011validation-error:0.269921\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 56 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.267028#011validation-error:0.269849\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 58 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.265796#011validation-error:0.270778\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 38 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.264986#011validation-error:0.269778\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.265233#011validation-error:0.268206\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.264106#011validation-error:0.266991\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.263262#011validation-error:0.267777\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.263508#011validation-error:0.267777\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.262558#011validation-error:0.266991\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.262558#011validation-error:0.266705\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.261466#011validation-error:0.26599\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 52 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.260094#011validation-error:0.265347\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 46 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.260129#011validation-error:0.26649\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.260129#011validation-error:0.265776\u001b[0m\n",
      "\u001b[34m[08:25:21] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.259988#011validation-error:0.265919\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.25939#011validation-error:0.265919\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 12 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.259742#011validation-error:0.265633\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.259425#011validation-error:0.266062\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.259847#011validation-error:0.265561\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.259671#011validation-error:0.26599\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.259495#011validation-error:0.266062\u001b[0m\n",
      "\u001b[34m[08:25:22] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.259073#011validation-error:0.265776\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.260094#011validation-error:0.265347\n",
      "\u001b[0m\n",
      "Training seconds: 60\n",
      "Billable seconds: 60\n",
      "CPU times: user 443 ms, sys: 29.5 ms, total: 473 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9e3ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a transformer object from the trained model. Using an instance count of 1 and an instance type of ml.m4.xlarge\n",
    "#       should be more than enough.\n",
    "xgb_transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0c6fbbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:30:16:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-05 08:30:16 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:30:16:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:30:16:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:30:16:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:30:20:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-10-05:08:30:20:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-10-05T08:30:20.477:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 596 ms, sys: 34 ms, total: 630 ms\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Start the transform job. Make sure to specify the content type and the split type of the test data.\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e229c53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-10-05-08-25-47-645/test.csv.out to data/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3419d164",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "68721e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in Y_pred.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5895280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7250311213252897"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e6c83e",
   "metadata": {},
   "source": [
    "## Train the model with a hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f79760b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 20, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a3fbbc",
   "metadata": {},
   "source": [
    "## Fit the Hyperparamereter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3aacf3b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................................................!\n",
      "CPU times: user 1.69 s, sys: 88.5 ms, total: 1.78 s\n",
      "Wall time: 27min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "#s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10ee6300",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xgboost-211004-1036-018-77293c4f', str)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_training_job = xgb_hyperparameter_tuner.best_training_job()\n",
    "best_training_job, type(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc24f79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-10-04 10:59:49 Starting - Preparing the instances for training\n",
      "2021-10-04 10:59:49 Downloading - Downloading input data\n",
      "2021-10-04 10:59:49 Training - Training image download completed. Training in progress.\n",
      "2021-10-04 10:59:49 Uploading - Uploading generated training model\n",
      "2021-10-04 10:59:49 Completed - Training job completed\n",
      "CPU times: user 84.7 ms, sys: 7.99 ms, total: 92.7 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_attached = sagemaker.estimator.Estimator.attach(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "24ca4894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.14 ms, sys: 0 ns, total: 8.14 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_tuned_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6121bb01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-10-04T11:09:33.255:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 745 ms, sys: 42.3 ms, total: 787 ms\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_tuned_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28f5b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-10-04-11-04-44-892/test.csv.out to data/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_tuned_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69d9094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8931a01d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7a7d1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in Y_pred.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d66e6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6983146605381595"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0b5575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We have a lot of test data, so we'll split it into batches of 100\n",
    "    # split the test data set into batches and evaluate using prediction endpoint    \n",
    "    prediction_batches = [predictor.predict(batch) for batch in np.array_split(test_features, 100)]\n",
    "    \n",
    "    # LinearLearner produces a `predicted_label` for each data point in a batch\n",
    "    # get the 'predicted_label' for every point in a batch\n",
    "    test_preds = np.concatenate([np.array([x.label['predicted_label'].float32_tensor.values[0] for x in batch]) \n",
    "                                 for batch in prediction_batches])\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3dd630c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1c553c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a97395d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = Y_test.values.flatten()\n",
    "test_preds = np.array(predictions)\n",
    "# calculate true positives, false positives, true negatives, false negatives\n",
    "tp = np.logical_and(test_labels, test_preds).sum()\n",
    "fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "\n",
    "# calculate binary classification metrics\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22c917e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (col)   0.0    1.0\n",
      "actual (row)                 \n",
      "0                 3997   4627\n",
      "1                 1674  10588\n",
      "\n",
      "Recall:     0.863\n",
      "Precision:  0.696\n",
      "Accuracy:   0.698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb7f908",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   test_features.astype('float32'), \n",
    "                   test_labels, \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4826c7",
   "metadata": {},
   "source": [
    "## Same process for viewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a904169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/preprocessed_features_viewed.csv', index_col=0)\n",
    "targets = pd.read_csv('data/preprocessed_targets_viewed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "26ca6172",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56895\n",
       "0    19382\n",
       "Name: viewed, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.viewed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469b28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b97724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bc64687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, targets, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36ff541d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186892</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210361</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230635</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239052</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201645</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305218</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239505</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25172 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        viewed\n",
       "251518       1\n",
       "186892       1\n",
       "210361       1\n",
       "230635       1\n",
       "170103       1\n",
       "...        ...\n",
       "239052       1\n",
       "201645       1\n",
       "305218       1\n",
       "231518       1\n",
       "239505       1\n",
       "\n",
       "[25172 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set values -1 to 0\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "abff10f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efad5e9e",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9ee2da47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test_viewed.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation_viewed.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train_viewed.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bb010",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5666df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cab0bd",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the createrd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9b07f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_viewed'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test_viewed.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation_viewed.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train_viewed.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b561cfc3",
   "metadata": {},
   "source": [
    "## Create Sagemaker Estimator and Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "85c5aa13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a SageMaker estimator using the container location determined in the previous cell.\n",
    "#       It is recommended that you use a single training instance of type ml.m4.xlarge. It is also\n",
    "#       recommended that you use 's3://{}/{}/output'.format(session.default_bucket(), prefix) as the\n",
    "#       output path.\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "# TODO: Set the XGBoost hyperparameters in the xgb object. Don't forget that in this case we have a binary\n",
    "#       label so we should be using the 'binary:logistic' objective.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10, \n",
    "                        num_round=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460e71ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "088402ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b5ca092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-23 06:40:06 Starting - Starting the training job...\n",
      "2021-09-23 06:40:08 Starting - Launching requested ML instancesProfilerReport-1632379206: InProgress\n",
      "......\n",
      "2021-09-23 06:41:25 Starting - Preparing the instances for training......\n",
      "2021-09-23 06:42:37 Downloading - Downloading input data\n",
      "2021-09-23 06:42:37 Training - Downloading the training image...\n",
      "2021-09-23 06:43:05 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] File size need to be processed in the node: 3.1mb. Available memory size in the node: 8389.71mb\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:42:58] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:42:58] 34240x10 matrix with 342400 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:42:58] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:42:58] 16865x10 matrix with 168650 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.187704#011validation-error:0.187311\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.187529#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.187325#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.187296#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.187091#011validation-error:0.186718\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.186945#011validation-error:0.186184\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.186828#011validation-error:0.186599\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.186945#011validation-error:0.186066\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.186857#011validation-error:0.185888\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.186857#011validation-error:0.186184\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.186887#011validation-error:0.186422\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.186478#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.185806#011validation-error:0.185532\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.185748#011validation-error:0.185532\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.185981#011validation-error:0.186125\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.185426#011validation-error:0.186007\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.18566#011validation-error:0.186007\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.185514#011validation-error:0.185947\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.185222#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.185134#011validation-error:0.185473\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.185251#011validation-error:0.185414\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 12 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.185222#011validation-error:0.185295\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.184755#011validation-error:0.185769\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.184871#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.184755#011validation-error:0.185769\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.184871#011validation-error:0.185651\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.184784#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.184755#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.184755#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.184784#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 34 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.184609#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.184609#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.185222#011validation-error:0.185295\n",
      "\u001b[0m\n",
      "\n",
      "2021-09-23 06:43:25 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 46\n",
      "CPU times: user 449 ms, sys: 17.3 ms, total: 467 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e28a54bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a transformer object from the trained model. Using an instance count of 1 and an instance type of ml.m4.xlarge\n",
    "#       should be more than enough.\n",
    "xgb_transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5ae03270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:59:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:59:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-09-23T06:48:58.944:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 576 ms, sys: 30.7 ms, total: 607 ms\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Start the transform job. Make sure to specify the content type and the split type of the test data.\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2c8278f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-09-23-06-44-25-632/test_viewed.csv.out to data/test_viewed.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7cd20838",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test_viewed.csv.out'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ff44c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in predictions.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "003d44d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098283807405053"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff46cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
