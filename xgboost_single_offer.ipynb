{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d142fe6",
   "metadata": {},
   "source": [
    "# ML Model with xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e40e6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f853c",
   "metadata": {},
   "source": [
    "## Import the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2a3ae2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/single_features.csv', index_col=0)\n",
    "targets = pd.read_csv('data/single_targets.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78c7cd57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6330, 15), (6330, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c86970cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>member_since_days</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>reward</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>duration</th>\n",
       "      <th>bogo</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.479956</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.487805</td>\n",
       "      <td>0.988889</td>\n",
       "      <td>0.126853</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.122222</td>\n",
       "      <td>0.151565</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073171</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.175178</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.536585</td>\n",
       "      <td>0.566667</td>\n",
       "      <td>0.422295</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6325</th>\n",
       "      <td>0.443823</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0.012081</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6326</th>\n",
       "      <td>0.597561</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.222954</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6327</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.180670</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6328</th>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.477778</td>\n",
       "      <td>0.147172</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6329</th>\n",
       "      <td>0.646341</td>\n",
       "      <td>0.288889</td>\n",
       "      <td>0.086766</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>120</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6330 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           age    income  member_since_days  M  F  O  U  reward  difficulty  \\\n",
       "0     0.500000  0.666667           0.479956  0  1  0  0      10          10   \n",
       "1     0.487805  0.988889           0.126853  0  1  0  0      10          10   \n",
       "2     0.646341  0.122222           0.151565  1  0  0  0      10          10   \n",
       "3     0.073171  0.133333           0.175178  1  0  0  0      10          10   \n",
       "4     0.536585  0.566667           0.422295  0  1  0  0      10          10   \n",
       "...        ...       ...                ... .. .. .. ..     ...         ...   \n",
       "6325  0.443823  0.393389           0.012081  0  0  0  1      10          10   \n",
       "6326  0.597561  0.555556           0.222954  1  0  0  0      10          10   \n",
       "6327  0.500000  0.700000           0.180670  0  1  0  0      10          10   \n",
       "6328  0.646341  0.477778           0.147172  1  0  0  0      10          10   \n",
       "6329  0.646341  0.288889           0.086766  1  0  0  0      10          10   \n",
       "\n",
       "      duration  bogo  email  mobile  social  web  \n",
       "0          120     1      1       1       1    1  \n",
       "1          120     1      1       1       1    1  \n",
       "2          120     1      1       1       1    1  \n",
       "3          120     1      1       1       1    1  \n",
       "4          120     1      1       1       1    1  \n",
       "...        ...   ...    ...     ...     ...  ...  \n",
       "6325       120     1      1       1       1    1  \n",
       "6326       120     1      1       1       1    1  \n",
       "6327       120     1      1       1       1    1  \n",
       "6328       120     1      1       1       1    1  \n",
       "6329       120     1      1       1       1    1  \n",
       "\n",
       "[6330 rows x 15 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a8f5c4",
   "metadata": {},
   "source": [
    "## Create Training, Validation and Testdata\n",
    "To avoid overfitting I split the train data additional in validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65437584",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95227b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, targets, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8bae3ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b7b055",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9fff0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'single_test.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'single_validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'single_train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d09626a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2089, 15)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a827cad",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a27e925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ece9d97",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the createrd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3d59aa51",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_binary'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'single_test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'single_validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'single_train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58945773",
   "metadata": {},
   "source": [
    "## Create Sagemaker Estimator and Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de047075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a SageMaker estimator using the container location determined in the previous cell.\n",
    "#       It is recommended that you use a single training instance of type ml.m4.xlarge. It is also\n",
    "#       recommended that you use 's3://{}/{}/output'.format(session.default_bucket(), prefix) as the\n",
    "#       output path.\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "# TODO: Set the XGBoost hyperparameters in the xgb object. Don't forget that in this case we have a binary\n",
    "#       label so we should be using the 'binary:logistic' objective.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10, \n",
    "                        num_round=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd2d2e69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6806a99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d75215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-01 14:51:39 Starting - Starting the training job...\n",
      "2021-10-01 14:52:03 Starting - Launching requested ML instancesProfilerReport-1633099899: InProgress\n",
      "......\n",
      "2021-10-01 14:53:03 Starting - Preparing the instances for training.........\n",
      "2021-10-01 14:54:29 Downloading - Downloading input data\n",
      "2021-10-01 14:54:29 Training - Downloading the training image..\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-10-01:14:54:51:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-10-01:14:54:51:INFO] File size need to be processed in the node: 0.36mb. Available memory size in the node: 8397.95mb\u001b[0m\n",
      "\u001b[34m[2021-10-01:14:54:51:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:54:51] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:54:51] 2841x15 matrix with 42615 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-10-01:14:54:51:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[14:54:51] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[14:54:51] 1400x15 matrix with 21000 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.242872#011validation-error:0.26\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.244632#011validation-error:0.258571\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.24076#011validation-error:0.249286\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.238296#011validation-error:0.252143\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.236536#011validation-error:0.251429\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.236888#011validation-error:0.250714\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.237592#011validation-error:0.249286\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.235832#011validation-error:0.247857\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.235128#011validation-error:0.251429\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 16 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.234073#011validation-error:0.250714\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.231609#011validation-error:0.25\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.231609#011validation-error:0.252143\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.230905#011validation-error:0.253571\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.230905#011validation-error:0.252857\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.228441#011validation-error:0.252857\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.229145#011validation-error:0.252857\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 14 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.228089#011validation-error:0.252857\u001b[0m\n",
      "\u001b[34m[14:54:51] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 2 extra nodes, 18 pruned nodes, max_depth=1\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.229145#011validation-error:0.252857\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.235832#011validation-error:0.247857\n",
      "\u001b[0m\n",
      "\n",
      "2021-10-01 14:55:03 Uploading - Uploading generated training model\n",
      "2021-10-01 14:55:03 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 46\n",
      "CPU times: user 470 ms, sys: 37.7 ms, total: 508 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31be1281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a transformer object from the trained model. Using an instance count of 1 and an instance type of ml.m4.xlarge\n",
    "#       should be more than enough.\n",
    "xgb_transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "29fad9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01:15:00:02:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m[2021-10-01:15:00:02:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01:15:00:02:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-10-01 15:00:02 +0000] [24] [INFO] Booting worker with pid: 24\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01:15:00:02:INFO] Model loaded successfully for worker : 24\u001b[0m\n",
      "\u001b[34m[2021-10-01:15:00:06:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-10-01:15:00:06:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\n",
      "\u001b[32m2021-10-01T15:00:05.960:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "CPU times: user 629 ms, sys: 46.3 ms, total: 675 ms\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Start the transform job. Make sure to specify the content type and the split type of the test data.\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5443eaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-10-01-14-55-22-039/single_test.csv.out to data/single_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2836f137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4515</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4706</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5612</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1181</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2343</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3889</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2919</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2089 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      binary_target\n",
       "185             1.0\n",
       "4515            0.0\n",
       "4706            1.0\n",
       "5612            1.0\n",
       "1181            1.0\n",
       "...             ...\n",
       "2343            1.0\n",
       "483             1.0\n",
       "3315            0.0\n",
       "3889            1.0\n",
       "2919            1.0\n",
       "\n",
       "[2089 rows x 1 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5b2ee3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'single_test.csv.out'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12b51c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in Y_pred.squeeze().values]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9aa697",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "94a87dcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7630445189085687"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9322674",
   "metadata": {},
   "source": [
    "## Train the model with a hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "70f841d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 20, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c77fe7",
   "metadata": {},
   "source": [
    "## Fit the Hyperparamereter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "9576d561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....................................................................................................................................................................................................................................................................................................................................................!\n",
      "CPU times: user 1.7 s, sys: 73.5 ms, total: 1.77 s\n",
      "Wall time: 28min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "#s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "8ea6f6a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xgboost-211001-1013-020-56d7fd91', str)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_training_job = xgb_hyperparameter_tuner.best_training_job()\n",
    "best_training_job, type(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "bbd71496",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-10-01 10:41:18 Starting - Preparing the instances for training\n",
      "2021-10-01 10:41:18 Downloading - Downloading input data\n",
      "2021-10-01 10:41:18 Training - Training image download completed. Training in progress.\n",
      "2021-10-01 10:41:18 Uploading - Uploading generated training model\n",
      "2021-10-01 10:41:18 Completed - Training job completed\n",
      "CPU times: user 83.6 ms, sys: 16.1 ms, total: 99.7 ms\n",
      "Wall time: 207 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_attached = sagemaker.estimator.Estimator.attach(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e4d58eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.4 ms, sys: 3 Âµs, total: 8.4 ms\n",
      "Wall time: 399 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_tuned_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "d82457ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-10-01 10:48:10 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[35m[2021-10-01 10:48:10 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-01:10:48:10:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-10-01:10:48:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-10-01:10:48:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-10-01:10:48:14:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2021-10-01:10:48:14:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-10-01T10:48:14.212:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 750 ms, sys: 53.7 ms, total: 803 ms\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_tuned_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "1de6bb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-10-01-10-43-12-747/regression_test.csv.out to data/regression_test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_tuned_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "337dd3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'regression_test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722c338e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "4d1a17e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in Y_pred.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "54484463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7300584123336206"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "51e658eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We have a lot of test data, so we'll split it into batches of 100\n",
    "    # split the test data set into batches and evaluate using prediction endpoint    \n",
    "    prediction_batches = [predictor.predict(batch) for batch in np.array_split(test_features, 100)]\n",
    "    \n",
    "    # LinearLearner produces a `predicted_label` for each data point in a batch\n",
    "    # get the 'predicted_label' for every point in a batch\n",
    "    test_preds = np.concatenate([np.array([x.label['predicted_label'].float32_tensor.values[0] for x in batch]) \n",
    "                                 for batch in prediction_batches])\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "9ea3120b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-131-e47b8570b196>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_labels' is not defined"
     ]
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "4adb86e5",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-132-5c39f5a0f7d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_preds' is not defined"
     ]
    }
   ],
   "source": [
    "np.array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "eeb4aeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = Y_test.values.flatten()\n",
    "test_preds = np.array(predictions)\n",
    "# calculate true positives, false positives, true negatives, false negatives\n",
    "tp = np.logical_and(test_labels, test_preds).sum()\n",
    "fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "\n",
    "# calculate binary classification metrics\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d643659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (col)   0.0    1.0\n",
      "actual (row)                 \n",
      "0                 5109   3547\n",
      "1                 2091  10139\n",
      "\n",
      "Recall:     0.829\n",
      "Precision:  0.741\n",
      "Accuracy:   0.730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfec7eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   test_features.astype('float32'), \n",
    "                   test_labels, \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dac838",
   "metadata": {},
   "source": [
    "## Same process for viewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc6553ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/preprocessed_features_viewed.csv', index_col=0)\n",
    "targets = pd.read_csv('data/preprocessed_targets_viewed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "368a56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56895\n",
       "0    19382\n",
       "Name: viewed, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.viewed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "664b1ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fa675f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2117c585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, targets, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "694c10df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186892</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210361</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230635</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239052</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201645</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305218</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239505</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25172 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        viewed\n",
       "251518       1\n",
       "186892       1\n",
       "210361       1\n",
       "230635       1\n",
       "170103       1\n",
       "...        ...\n",
       "239052       1\n",
       "201645       1\n",
       "305218       1\n",
       "231518       1\n",
       "239505       1\n",
       "\n",
       "[25172 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set values -1 to 0\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "80907060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b69c09",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4f449713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test_viewed.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation_viewed.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train_viewed.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93dd5030",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "bca37a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73d1d4ea",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the createrd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "63c29d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_viewed'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test_viewed.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation_viewed.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train_viewed.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cddb529f",
   "metadata": {},
   "source": [
    "## Create Sagemaker Estimator and Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "27cb2cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a SageMaker estimator using the container location determined in the previous cell.\n",
    "#       It is recommended that you use a single training instance of type ml.m4.xlarge. It is also\n",
    "#       recommended that you use 's3://{}/{}/output'.format(session.default_bucket(), prefix) as the\n",
    "#       output path.\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "# TODO: Set the XGBoost hyperparameters in the xgb object. Don't forget that in this case we have a binary\n",
    "#       label so we should be using the 'binary:logistic' objective.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10, \n",
    "                        num_round=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc66b928",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2451c427",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "9f5574d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-23 06:40:06 Starting - Starting the training job...\n",
      "2021-09-23 06:40:08 Starting - Launching requested ML instancesProfilerReport-1632379206: InProgress\n",
      "......\n",
      "2021-09-23 06:41:25 Starting - Preparing the instances for training......\n",
      "2021-09-23 06:42:37 Downloading - Downloading input data\n",
      "2021-09-23 06:42:37 Training - Downloading the training image...\n",
      "2021-09-23 06:43:05 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] File size need to be processed in the node: 3.1mb. Available memory size in the node: 8389.71mb\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:42:58] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:42:58] 34240x10 matrix with 342400 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:42:58] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:42:58] 16865x10 matrix with 168650 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.187704#011validation-error:0.187311\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.187529#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.187325#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.187296#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.187091#011validation-error:0.186718\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.186945#011validation-error:0.186184\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.186828#011validation-error:0.186599\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.186945#011validation-error:0.186066\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.186857#011validation-error:0.185888\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.186857#011validation-error:0.186184\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.186887#011validation-error:0.186422\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.186478#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.185806#011validation-error:0.185532\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.185748#011validation-error:0.185532\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.185981#011validation-error:0.186125\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.185426#011validation-error:0.186007\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.18566#011validation-error:0.186007\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.185514#011validation-error:0.185947\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.185222#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.185134#011validation-error:0.185473\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.185251#011validation-error:0.185414\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 12 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.185222#011validation-error:0.185295\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.184755#011validation-error:0.185769\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.184871#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.184755#011validation-error:0.185769\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.184871#011validation-error:0.185651\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.184784#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.184755#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.184755#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.184784#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 34 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.184609#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.184609#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.185222#011validation-error:0.185295\n",
      "\u001b[0m\n",
      "\n",
      "2021-09-23 06:43:25 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 46\n",
      "CPU times: user 449 ms, sys: 17.3 ms, total: 467 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "488db3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a transformer object from the trained model. Using an instance count of 1 and an instance type of ml.m4.xlarge\n",
    "#       should be more than enough.\n",
    "xgb_transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d5cf1393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:59:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:59:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-09-23T06:48:58.944:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 576 ms, sys: 30.7 ms, total: 607 ms\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Start the transform job. Make sure to specify the content type and the split type of the test data.\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b7c40a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-09-23-06-44-25-632/test_viewed.csv.out to data/test_viewed.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "fa012aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test_viewed.csv.out'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1f7c121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in predictions.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "412f7067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098283807405053"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab6432f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
