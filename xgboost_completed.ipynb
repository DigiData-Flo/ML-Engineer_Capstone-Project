{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5e3be9e",
   "metadata": {},
   "source": [
    "# ML Model with xgboost\n",
    "\n",
    "The selected machine learning algorith is xgboost. Detailed information about xgboost can be found here. [xgboost](https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "defa2ad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7495b0fa",
   "metadata": {},
   "source": [
    "## Import the preprocessed data\n",
    "\n",
    "To start the machine learning process I load my preprocessed csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36ac60da",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/features_completed.csv', index_col=0)\n",
    "labels = pd.read_csv('data/labels_completed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0820b025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((63288, 11), (63288, 1))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "41c97fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>F</th>\n",
       "      <th>M</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>member_since_days</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.180723</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1630</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.072289</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.445783</td>\n",
       "      <td>0.488889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1248</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age    income  F  M  O  U  member_since_days  email  mobile  social  \\\n",
       "0  0.180723  0.466667  0  1  0  0               1630      1       1       1   \n",
       "1  0.072289  0.333333  1  0  0  0               1791      1       1       1   \n",
       "2  0.445783  0.488889  1  0  0  0               1248      1       1       1   \n",
       "\n",
       "   web  \n",
       "0    1  \n",
       "1    1  \n",
       "2    1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c1d2393d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>binary_target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   binary_target\n",
       "0              1\n",
       "1              1\n",
       "2              1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9a8a38",
   "metadata": {},
   "source": [
    "## Create Training, Validation and Testdata\n",
    "\n",
    "The loaded data is already preprocessed, there are no further data cleaning steps necessary. However, we do need to split the rows in the dataset up into train, test and validation sets.\n",
    "To avoid overfitting I split the train data additional in validation data. To simplify the splitting I use the train_test_split method from sklear.model_selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3c0a1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5bcca5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, labels, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bfef6a",
   "metadata": {},
   "source": [
    "To control my input an output I define a data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bd9d63b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a2085cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5154fa3c",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data\n",
    "\n",
    "The training and validation data needs the groundtruth as first column in the dataset. The test data have no groundtruth column.\n",
    "\n",
    "The xgboost does not accept a header row and an index column. This is to consider when write the training and test data to visualization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2a536590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf4b88a",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions\n",
    "In addition to the modules above, we need to import the various bits of SageMaker that we will be using. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ba057a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dafdcfb",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the created files\n",
    "\n",
    "The data will now be uploasded to s3 storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "365157b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_completed'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9369fd3f",
   "metadata": {},
   "source": [
    "## Create Sagemaker Estimator and Hyperparamaters\n",
    "\n",
    "I use the amazon build in estimator with a xgboost container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fefa3470",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a SageMaker estimator using the container location determined in the previous cell.\n",
    "#       It is recommended that you use a single training instance of type ml.m4.xlarge. It is also\n",
    "#       recommended that you use 's3://{}/{}/output'.format(session.default_bucket(), prefix) as the\n",
    "#       output path.\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "# TODO: Set the XGBoost hyperparameters in the xgb object. Don't forget that in this case we have a binary\n",
    "#       label so we should be using the 'binary:logistic' objective.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10, \n",
    "                        num_round=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d363c338",
   "metadata": {},
   "source": [
    "After defining the xgboost estimator and the hyperparameters, the input train locations will be specified as training inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "582e12c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af919e9",
   "metadata": {},
   "source": [
    "Now it's time to train the estimator. To avoid over fitting a validation set is also used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4a4f8e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-10-07 10:58:23 Starting - Starting the training job...\n",
      "2021-10-07 10:58:46 Starting - Launching requested ML instancesProfilerReport-1633604303: InProgress\n",
      "...\n",
      "2021-10-07 10:59:12 Starting - Preparing the instances for training............\n",
      "2021-10-07 11:01:19 Downloading - Downloading input data\n",
      "2021-10-07 11:01:19 Training - Downloading the training image...\n",
      "2021-10-07 11:01:54 Uploading - Uploading generated training model\n",
      "2021-10-07 11:01:54 Completed - Training job completed\n",
      "\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:01:41:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:01:41:INFO] File size need to be processed in the node: 2.45mb. Available memory size in the node: 8389.14mb\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:01:41:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[11:01:41] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[11:01:41] 28409x11 matrix with 312499 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:01:41:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[11:01:41] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[11:01:41] 13993x11 matrix with 153923 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.300503#011validation-error:0.304224\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 6 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.299236#011validation-error:0.303437\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.296139#011validation-error:0.301293\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.296033#011validation-error:0.301651\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.297019#011validation-error:0.301937\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.29554#011validation-error:0.302937\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.294132#011validation-error:0.301008\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.294555#011validation-error:0.301079\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 42 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.293639#011validation-error:0.301436\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.293569#011validation-error:0.300007\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 48 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.292654#011validation-error:0.300436\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 14 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.291985#011validation-error:0.301008\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 4 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.290964#011validation-error:0.301293\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.291351#011validation-error:0.301508\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 50 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.290014#011validation-error:0.300579\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.290049#011validation-error:0.301293\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.289803#011validation-error:0.300936\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.289028#011validation-error:0.300865\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.289767#011validation-error:0.301293\u001b[0m\n",
      "\u001b[34m[11:01:41] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.288324#011validation-error:0.301079\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.293569#011validation-error:0.300007\n",
      "\u001b[0m\n",
      "Training seconds: 52\n",
      "Billable seconds: 52\n",
      "CPU times: user 420 ms, sys: 45.1 ms, total: 465 ms\n",
      "Wall time: 3min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753d7e26",
   "metadata": {},
   "source": [
    "### Test the model\n",
    "\n",
    "Now that I have fit the model to the training data, using the validation data to avoid overfitting, I can test the model. To do this I will make use of SageMaker's Batch Transform functionality. \n",
    "First I have to create an estimator transformer object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1a8bfde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a transformer object from the trained model. Using an instance count of 1 and an instance type of ml.m4.xlarge\n",
    "#       should be more than enough.\n",
    "xgb_transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b681e2",
   "metadata": {},
   "source": [
    "Now I can start the transformation. To do this I have to give the location to the test data, the type of data and a split type, in case that our test data is to large to send it once. Therefore our data is organized in rows the split type is 'Line'. The type of data is a test based csv file. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "db26a641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-10-07 11:07:20 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35m[2021-10-07 11:07:20 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[35m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-07:11:07:20:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:07:24:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-10-07:11:07:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-10-07:11:07:24:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2021-10-07:11:07:24:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-10-07T11:07:24.276:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 634 ms, sys: 36.6 ms, total: 671 ms\n",
      "Wall time: 5min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Start the transform job. Make sure to specify the content type and the split type of the test data.\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "81ee2cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-10-07-11-02-13-129/test.csv.out to data/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57219836",
   "metadata": {},
   "source": [
    "After transforming the results I can download the predictions for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0f6d13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d87f6cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.749801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.741089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.266861</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "0  0.749801\n",
       "1  0.741089\n",
       "2  0.266861"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9399d3",
   "metadata": {},
   "source": [
    "the predictions must be round to integers to get a binary output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "73c13e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in Y_pred.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed87fcb9",
   "metadata": {},
   "source": [
    "Now I can use the accuracy_score method from "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e487800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6975964761083979"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7b975ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = Y_test.values.flatten()\n",
    "test_preds = np.array(predictions)\n",
    "# calculate true positives, false positives, true negatives, false negatives\n",
    "tp = np.logical_and(test_labels, test_preds).sum()\n",
    "fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "\n",
    "# calculate binary classification metrics\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a344949a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (col)   0.0   1.0\n",
      "actual (row)                \n",
      "0                 5258  3385\n",
      "1                 2931  9312\n",
      "\n",
      "Recall:     0.761\n",
      "Precision:  0.733\n",
      "Accuracy:   0.698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "655fc3ce",
   "metadata": {},
   "source": [
    "## Train the model with a hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "847ea4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tuner import IntegerParameter, ContinuousParameter, HyperparameterTuner\n",
    "\n",
    "xgb_hyperparameter_tuner = HyperparameterTuner(estimator = xgb, # The estimator object to use as the basis for the training jobs.\n",
    "                                               objective_metric_name = 'validation:rmse', # The metric used to compare trained models.\n",
    "                                               objective_type = 'Minimize', # Whether we wish to minimize or maximize the metric.\n",
    "                                               max_jobs = 20, # The total number of models to train\n",
    "                                               max_parallel_jobs = 3, # The number of models to train in parallel\n",
    "                                               hyperparameter_ranges = {\n",
    "                                                    'max_depth': IntegerParameter(3, 12),\n",
    "                                                    'eta'      : ContinuousParameter(0.05, 0.5),\n",
    "                                                    'min_child_weight': IntegerParameter(2, 8),\n",
    "                                                    'subsample': ContinuousParameter(0.5, 0.9),\n",
    "                                                    'gamma': ContinuousParameter(0, 10),\n",
    "                                               })"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd091e2",
   "metadata": {},
   "source": [
    "## Fit the Hyperparamereter Tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "93c39fd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...................................................................................................................................................................................................................................................................................................................................!\n",
      "CPU times: user 1.69 s, sys: 88.5 ms, total: 1.78 s\n",
      "Wall time: 27min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# This is a wrapper around the location of our train and validation data, to make sure that SageMaker\n",
    "# knows our data is in csv format.\n",
    "#s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')\n",
    "\n",
    "xgb_hyperparameter_tuner.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "955dc602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('xgboost-211004-1036-018-77293c4f', str)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_training_job = xgb_hyperparameter_tuner.best_training_job()\n",
    "best_training_job, type(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c571ecf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2021-10-04 10:59:49 Starting - Preparing the instances for training\n",
      "2021-10-04 10:59:49 Downloading - Downloading input data\n",
      "2021-10-04 10:59:49 Training - Training image download completed. Training in progress.\n",
      "2021-10-04 10:59:49 Uploading - Uploading generated training model\n",
      "2021-10-04 10:59:49 Completed - Training job completed\n",
      "CPU times: user 84.7 ms, sys: 7.99 ms, total: 92.7 ms\n",
      "Wall time: 194 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_attached = sagemaker.estimator.Estimator.attach(best_training_job)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a02f38a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.14 ms, sys: 0 ns, total: 8.14 ms\n",
      "Wall time: 363 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_tuned_transformer = xgb_attached.transformer(instance_count = 1, instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1bad75c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35mArguments: serve\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-10-04 11:09:29 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[35m[2021-10-04 11:09:29 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[35m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)', 'urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:29:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-10-04:11:09:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:33:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[35m[2021-10-04:11:09:33:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-10-04T11:09:33.255:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 745 ms, sys: 42.3 ms, total: 787 ms\n",
      "Wall time: 5min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb_tuned_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "90a76ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-10-04-11-04-44-892/test.csv.out to data/test.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_tuned_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a2216c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = pd.read_csv(os.path.join(data_dir, 'test.csv.out'), header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406b316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "532a50c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in Y_pred.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f155d9dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6983146605381595"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c64a9572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We have a lot of test data, so we'll split it into batches of 100\n",
    "    # split the test data set into batches and evaluate using prediction endpoint    \n",
    "    prediction_batches = [predictor.predict(batch) for batch in np.array_split(test_features, 100)]\n",
    "    \n",
    "    # LinearLearner produces a `predicted_label` for each data point in a batch\n",
    "    # get the 'predicted_label' for every point in a batch\n",
    "    test_preds = np.concatenate([np.array([x.label['predicted_label'].float32_tensor.values[0] for x in batch]) \n",
    "                                 for batch in prediction_batches])\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # printing a table of metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e806513a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a28187c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., ..., 1., 1., 1.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d0f7260b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = Y_test.values.flatten()\n",
    "test_preds = np.array(predictions)\n",
    "# calculate true positives, false positives, true negatives, false negatives\n",
    "tp = np.logical_and(test_labels, test_preds).sum()\n",
    "fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "\n",
    "# calculate binary classification metrics\n",
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8662c047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction (col)   0.0    1.0\n",
      "actual (row)                 \n",
      "0                 3997   4627\n",
      "1                 1674  10588\n",
      "\n",
      "Recall:     0.863\n",
      "Precision:  0.696\n",
      "Accuracy:   0.698\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pd.crosstab(test_labels, test_preds, rownames=['actual (row)'], colnames=['prediction (col)']))\n",
    "print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9178ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Metrics for simple, LinearLearner.\\n')\n",
    "\n",
    "# get metrics for linear predictor\n",
    "metrics = evaluate(linear_predictor, \n",
    "                   test_features.astype('float32'), \n",
    "                   test_labels, \n",
    "                   verbose=True) # verbose means we'll print out the metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2881843",
   "metadata": {},
   "source": [
    "## Same process for viewed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "82720fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/preprocessed_features_viewed.csv', index_col=0)\n",
    "targets = pd.read_csv('data/preprocessed_targets_viewed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3c8b4694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56895\n",
       "0    19382\n",
       "Name: viewed, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.viewed.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf78a8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6944946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "93f66ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, targets, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "390c34ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186892</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210361</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>230635</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170103</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239052</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201645</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305218</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231518</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239505</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25172 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        viewed\n",
       "251518       1\n",
       "186892       1\n",
       "210361       1\n",
       "230635       1\n",
       "170103       1\n",
       "...        ...\n",
       "239052       1\n",
       "201645       1\n",
       "305218       1\n",
       "231518       1\n",
       "239505       1\n",
       "\n",
       "[25172 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set values -1 to 0\n",
    "Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7669f936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d25a48",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "465bed8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "X_test.to_csv(os.path.join(data_dir, 'test_viewed.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation_viewed.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train_viewed.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0b5143",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5a0c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9092e0",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the createrd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "694bbb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_viewed'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test_viewed.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation_viewed.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train_viewed.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4de3c1a0",
   "metadata": {},
   "source": [
    "## Create Sagemaker Estimator and Hyperparamaters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dde41f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a SageMaker estimator using the container location determined in the previous cell.\n",
    "#       It is recommended that you use a single training instance of type ml.m4.xlarge. It is also\n",
    "#       recommended that you use 's3://{}/{}/output'.format(session.default_bucket(), prefix) as the\n",
    "#       output path.\n",
    "\n",
    "container = sagemaker.image_uris.retrieve('xgboost', session.boto_region_name, 'latest')\n",
    "\n",
    "xgb = sagemaker.estimator.Estimator(container,\n",
    "                                    role=role,\n",
    "                                    instance_count=1,\n",
    "                                    instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(session.default_bucket(), prefix),\n",
    "                                    sagemaker_session=session)\n",
    "\n",
    "\n",
    "# TODO: Set the XGBoost hyperparameters in the xgb object. Don't forget that in this case we have a binary\n",
    "#       label so we should be using the 'binary:logistic' objective.\n",
    "xgb.set_hyperparameters(max_depth=5,\n",
    "                        eta=0.2,\n",
    "                        gamma=4,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.8,\n",
    "                        objective='binary:logistic',\n",
    "                        early_stopping_rounds=10, \n",
    "                        num_round=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d292b8e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1e75b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#s3_input_train = sagemaker.s3_input(s3_data=train_location, content_type='csv')\n",
    "#s3_input_validation = sagemaker.s3_input(s3_data=val_location, content_type='csv')\n",
    "\n",
    "s3_input_train = sagemaker.inputs.TrainingInput(s3_data=train_location, content_type='csv')\n",
    "s3_input_validation = sagemaker.inputs.TrainingInput(s3_data=val_location, content_type='csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "97d14d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-09-23 06:40:06 Starting - Starting the training job...\n",
      "2021-09-23 06:40:08 Starting - Launching requested ML instancesProfilerReport-1632379206: InProgress\n",
      "......\n",
      "2021-09-23 06:41:25 Starting - Preparing the instances for training......\n",
      "2021-09-23 06:42:37 Downloading - Downloading input data\n",
      "2021-09-23 06:42:37 Training - Downloading the training image...\n",
      "2021-09-23 06:43:05 Uploading - Uploading generated training model\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Running standalone xgboost training.\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] File size need to be processed in the node: 3.1mb. Available memory size in the node: 8389.71mb\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:42:58] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:42:58] 34240x10 matrix with 342400 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:42:58:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[06:42:58] S3DistributionType set as FullyReplicated\u001b[0m\n",
      "\u001b[34m[06:42:58] 16865x10 matrix with 168650 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 10 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34mMultiple eval metrics have been passed: 'validation-error' will be used for early stopping.\n",
      "\u001b[0m\n",
      "\u001b[34mWill train until validation-error hasn't improved in 10 rounds.\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 12 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 34 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.189398#011validation-error:0.18826\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.187704#011validation-error:0.187311\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.187529#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.187325#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.187296#011validation-error:0.187015\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.187091#011validation-error:0.186718\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.186945#011validation-error:0.186184\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 32 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.186828#011validation-error:0.186599\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 40 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.186945#011validation-error:0.186066\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.186857#011validation-error:0.185888\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.186857#011validation-error:0.186184\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.186887#011validation-error:0.186422\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.186478#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 44 extra nodes, 18 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.185806#011validation-error:0.185532\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 30 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.185748#011validation-error:0.185532\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 26 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.185981#011validation-error:0.186125\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.185426#011validation-error:0.186007\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 24 extra nodes, 24 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.18566#011validation-error:0.186007\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 30 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.185514#011validation-error:0.185947\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 22 extra nodes, 20 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.185222#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.185134#011validation-error:0.185473\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 8 extra nodes, 30 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.185251#011validation-error:0.185414\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 4 extra nodes, 12 pruned nodes, max_depth=2\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.185222#011validation-error:0.185295\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 36 extra nodes, 22 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.184755#011validation-error:0.185769\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 28 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.184871#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 20 extra nodes, 8 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.184755#011validation-error:0.185769\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 28 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.184871#011validation-error:0.185651\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 12 extra nodes, 16 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.184784#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 18 extra nodes, 26 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.184755#011validation-error:0.18571\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 14 extra nodes, 34 pruned nodes, max_depth=5\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.184755#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 18 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.184784#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 10 extra nodes, 34 pruned nodes, max_depth=4\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.184609#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34m[06:42:58] src/tree/updater_prune.cc:74: tree pruning end, 1 roots, 0 extra nodes, 20 pruned nodes, max_depth=0\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.184609#011validation-error:0.185591\u001b[0m\n",
      "\u001b[34mStopping. Best iteration:\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.185222#011validation-error:0.185295\n",
      "\u001b[0m\n",
      "\n",
      "2021-09-23 06:43:25 Completed - Training job completed\n",
      "Training seconds: 46\n",
      "Billable seconds: 46\n",
      "CPU times: user 449 ms, sys: 17.3 ms, total: 467 ms\n",
      "Wall time: 3min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3c1dae6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Create a transformer object from the trained model. Using an instance count of 1 and an instance type of ml.m4.xlarge\n",
    "#       should be more than enough.\n",
    "xgb_transformer = xgb.transformer(instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "25af538c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................\u001b[34mArguments: serve\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Starting gunicorn 19.9.0\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Listening at: http://0.0.0.0:8080 (1)\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [1] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [20] [INFO] Booting worker with pid: 20\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [21] [INFO] Booting worker with pid: 21\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [22] [INFO] Booting worker with pid: 22\u001b[0m\n",
      "\u001b[34m[2021-09-23 06:48:55 +0000] [23] [INFO] Booting worker with pid: 23\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 21\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 20\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 22\u001b[0m\n",
      "\u001b[34m/opt/amazon/lib/python3.7/site-packages/gunicorn/workers/ggevent.py:65: MonkeyPatchWarning: Monkey-patching ssl after ssl has already been imported may lead to errors, including RecursionError on Python 3.6. It may also silently lead to incorrect behaviour on Python 3.7. Please monkey-patch earlier. See https://github.com/gevent/gevent/issues/1016. Modules that had direct imports (NOT patched): ['urllib3.util (/opt/amazon/lib/python3.7/site-packages/urllib3/util/__init__.py)', 'urllib3.util.ssl_ (/opt/amazon/lib/python3.7/site-packages/urllib3/util/ssl_.py)']. \n",
      "  monkey.patch_all(subprocess=True)\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:55:INFO] Model loaded successfully for worker : 23\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:59:INFO] Sniff delimiter as ','\u001b[0m\n",
      "\u001b[34m[2021-09-23:06:48:59:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[32m2021-09-23T06:48:58.944:[sagemaker logs]: MaxConcurrentTransforms=4, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\n",
      "CPU times: user 576 ms, sys: 30.7 ms, total: 607 ms\n",
      "Wall time: 5min 12s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# TODO: Start the transform job. Make sure to specify the content type and the split type of the test data.\n",
    "xgb_transformer.transform(test_location, content_type='text/csv', split_type='Line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9cc8b2d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-eu-central-1-647915836300/xgboost-2021-09-23-06-44-25-632/test_viewed.csv.out to data/test_viewed.csv.out\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp --recursive $xgb_transformer.output_path $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "33eb89f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.read_csv(os.path.join(data_dir, 'test_viewed.csv.out'), header=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "dfb1aa36",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = [round(num) for num in predictions.squeeze().values]\n",
    "#predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "080db855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8098283807405053"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(Y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3f23a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
