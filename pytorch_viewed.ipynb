{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2b5eed2",
   "metadata": {},
   "source": [
    "# ML Model with pyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b2dc2e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import time\n",
    "from time import gmtime, strftime\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61d35101",
   "metadata": {},
   "source": [
    "## Import the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c65642ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.read_csv('data/preprocessed_features_viewed.csv', index_col=0)\n",
    "targets = pd.read_csv('data/preprocessed_targets_viewed.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7335792",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((76277, 10), (76277, 1))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "681d29b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.602410</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.566265</td>\n",
       "      <td>0.255556</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306125</th>\n",
       "      <td>0.132530</td>\n",
       "      <td>0.311111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306128</th>\n",
       "      <td>0.650602</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306130</th>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306132</th>\n",
       "      <td>0.325301</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306134</th>\n",
       "      <td>0.783133</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>76277 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             age    income  M  F  O  U  email  mobile  social  web\n",
       "0       0.438476  0.393389  0  0  0  1    1.0     1.0     0.0  1.0\n",
       "2       0.602410  0.444444  1  0  0  0    1.0     1.0     0.0  1.0\n",
       "4       0.438476  0.393389  0  0  0  1    1.0     1.0     0.0  1.0\n",
       "6       0.438476  0.393389  0  0  0  1    1.0     1.0     0.0  1.0\n",
       "8       0.566265  0.255556  1  0  0  0    1.0     1.0     0.0  1.0\n",
       "...          ...       ... .. .. .. ..    ...     ...     ...  ...\n",
       "306125  0.132530  0.311111  0  1  0  0    1.0     1.0     1.0  1.0\n",
       "306128  0.650602  0.388889  0  1  0  0    1.0     1.0     1.0  1.0\n",
       "306130  0.438476  0.393389  0  0  0  1    1.0     1.0     1.0  1.0\n",
       "306132  0.325301  0.266667  0  1  0  0    1.0     1.0     1.0  1.0\n",
       "306134  0.783133  0.222222  0  1  0  0    1.0     1.0     1.0  1.0\n",
       "\n",
       "[76277 rows x 10 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7573065f",
   "metadata": {},
   "source": [
    "## Create Training, Validation and Testdata\n",
    "To avoid overfitting I split the train data additional in validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1577fd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f483003f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the dataset into 2/3 training and 1/3 testing sets.\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(features, targets, test_size=0.33)\n",
    "\n",
    "# Then we split the training set further into 2/3 training and 1/3 validation sets.\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71b3f440",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((34240, 10), (16865, 10))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4d7e56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data directory and make sure that the directory exists\n",
    "data_dir = 'data'\n",
    "if not os.path.exists(data_dir):\n",
    "    os.makedirs(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ba8d535",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    56895\n",
       "0    19382\n",
       "Name: viewed, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([targets, features], axis=1)\n",
    "df.viewed.value_counts()\n",
    "#df.query('viewed == 1 and completed == 1').social.value_counts()\n",
    "#df.query('viewed == -1 and completed == 1').social.value_counts()\n",
    "#df.query('viewed == 1 and completed == 0').social.value_counts()\n",
    "#df.query('viewed == -1 and completed == 0').social.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983f914c",
   "metadata": {},
   "source": [
    "## Create csv files for test, validation and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c8115070",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>viewed</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>M</th>\n",
       "      <th>F</th>\n",
       "      <th>O</th>\n",
       "      <th>U</th>\n",
       "      <th>email</th>\n",
       "      <th>mobile</th>\n",
       "      <th>social</th>\n",
       "      <th>web</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>253181</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178496</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299287</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239201</th>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174983</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290422</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252605</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300012</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50344 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        viewed       age    income    M    F    O    U  email  mobile  social  \\\n",
       "253181     1.0       NaN       NaN  NaN  NaN  NaN  NaN    NaN     NaN     NaN   \n",
       "178496     1.0       NaN       NaN  NaN  NaN  NaN  NaN    NaN     NaN     NaN   \n",
       "49         1.0       NaN       NaN  NaN  NaN  NaN  NaN    NaN     NaN     NaN   \n",
       "299287     1.0       NaN       NaN  NaN  NaN  NaN  NaN    NaN     NaN     NaN   \n",
       "239201     0.0       NaN       NaN  NaN  NaN  NaN  NaN    NaN     NaN     NaN   \n",
       "...        ...       ...       ...  ...  ...  ...  ...    ...     ...     ...   \n",
       "174983     NaN  0.746988  0.500000  1.0  0.0  0.0  0.0    1.0     1.0     1.0   \n",
       "290422     NaN  0.469880  0.388889  1.0  0.0  0.0  0.0    1.0     1.0     1.0   \n",
       "194609     NaN  0.349398  0.400000  0.0  1.0  0.0  0.0    1.0     1.0     1.0   \n",
       "252605     NaN  0.710843  0.811111  1.0  0.0  0.0  0.0    1.0     1.0     1.0   \n",
       "300012     NaN  0.397590  0.766667  1.0  0.0  0.0  0.0    1.0     1.0     1.0   \n",
       "\n",
       "        web  \n",
       "253181  NaN  \n",
       "178496  NaN  \n",
       "49      NaN  \n",
       "299287  NaN  \n",
       "239201  NaN  \n",
       "...     ...  \n",
       "174983  1.0  \n",
       "290422  1.0  \n",
       "194609  1.0  \n",
       "252605  0.0  \n",
       "300012  1.0  \n",
       "\n",
       "[50344 rows x 11 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([Y_test, X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "27ff4671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use pandas to save our test, train and validation data to csv files. Note that we make sure not to include header\n",
    "# information or an index as this is required by the built in algorithms provided by Amazon. Also, for the train and\n",
    "# validation data, it is assumed that the first entry in each row is the target variable.\n",
    "\n",
    "pd.concat([Y_test, X_test], axis=1).to_csv(os.path.join(data_dir, 'test_viewed.csv'), header=False, index=False)\n",
    "\n",
    "pd.concat([Y_val, X_val], axis=1).to_csv(os.path.join(data_dir, 'validation_viewed.csv'), header=False, index=False)\n",
    "pd.concat([Y_train, X_train], axis=1).to_csv(os.path.join(data_dir, 'train_viewed.csv'), header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d619f5",
   "metadata": {},
   "source": [
    "## Import the sagemaker specific classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5ca93e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "#from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "# This is an object that represents the SageMaker session that we are currently operating in. This\n",
    "# object contains some useful information that we will need to access later such as our region.\n",
    "session = sagemaker.Session()\n",
    "\n",
    "# This is an object that represents the IAM role that we are currently assigned. When we construct\n",
    "# and launch the training job later we will need to tell it what IAM role it should have. Since our\n",
    "# use case is relatively simple we will simply assign the training job the role we currently have.\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ea346c",
   "metadata": {},
   "source": [
    "## Define a prefix for s3 data upload and upload the createrd files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59c1a584",
   "metadata": {},
   "outputs": [],
   "source": [
    "prefix = 'capstone_completed'\n",
    "\n",
    "test_location = session.upload_data(os.path.join(data_dir, 'test_viewed.csv'), key_prefix=prefix)\n",
    "val_location = session.upload_data(os.path.join(data_dir, 'validation_viewed.csv'), key_prefix=prefix)\n",
    "train_location = session.upload_data(os.path.join(data_dir, 'train_viewed.csv'), key_prefix=prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7653734d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-eu-central-1-647915836300/capstone_pytorch\n"
     ]
    }
   ],
   "source": [
    "# specify where to upload in S3\n",
    "prefix = 'capstone_pytorch'\n",
    "bucket = session.default_bucket()\n",
    "# upload to S3\n",
    "input_data = session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "61887b58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-eu-central-1-647915836300/capstone_pytorch'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa813c75",
   "metadata": {},
   "source": [
    "### Create a PyTorch Estimator\n",
    "\n",
    "You've had some practice instantiating built-in models in SageMaker. All estimators require some constructor arguments to be passed in. When a custom model is constructed in SageMaker, an **entry point** must be specified. The entry_point is the training script that will be executed when the model is trained; the `train.py` function you specified above! \n",
    "\n",
    "#### Model size\n",
    " I found an interisting article how to choose the number and size of hidden layers [choosing-number-hidden-layers-neurons-neural-networks](https://www.linkedin.com/pulse/choosing-number-hidden-layers-neurons-neural-networks-sachdev/)\n",
    "\n",
    "#### Instance Types\n",
    "\n",
    "It is suggested that you use instances that are available in the free tier of usage: `'ml.c4.xlarge'` for training and `'ml.t2.medium'` for deployment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ca15a7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input features\n",
    "input_dim = features.shape[1]\n",
    "# choose 3 hidden layers for input features count\n",
    "# Start with 8 neurons for layer 1\n",
    "hidden_1 = 8\n",
    "hidden_2 = 4\n",
    "hidden_3 = 2\n",
    "output_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "72ee2e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 8, 4, 2, 1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim, hidden_1, hidden_2, hidden_3, output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b809eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-training:1.9.0-gpu-py38-cu111-ubuntu20.04'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "container = '763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-training:1.9.0-gpu-py38-cu111-ubuntu20.04'\n",
    "container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "68352ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import a PyTorch wrapper\n",
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "# specify an output path\n",
    "output_path = 's3://{}/{}'.format(bucket, prefix)\n",
    "\n",
    "# instantiate a pytorch estimator\n",
    "estimator = PyTorch(entry_point='train.py',\n",
    "                    source_dir='source',\n",
    "                    role=role,\n",
    "                    image_uri=container,\n",
    "                    #framework_version='latest',\n",
    "                    instance_count=1,\n",
    "                    instance_type='ml.c4.xlarge',\n",
    "                    output_path=output_path,\n",
    "                    sagemaker_session=session,\n",
    "                    hyperparameters={\n",
    "                        'input_dim': input_dim,\n",
    "                        'hidden_1': hidden_1,\n",
    "                        'hidden_2': hidden_2,\n",
    "                        'hidden_3': hidden_3,\n",
    "                        'output_dim': 1,\n",
    "                        'epochs': 80, # could change to higher\n",
    "                        'batch_size': 100\n",
    "                    })\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f215f4",
   "metadata": {},
   "source": [
    "## Train the Estimator\n",
    "\n",
    "After instantiating your estimator, train it with a call to `.fit()`. The `train.py` file explicitly loads in `.csv` data, so you do not need to convert the input data to any other format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "ae2118fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 1e+03 ns, total: 4 µs\n",
      "Wall time: 7.39 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#estimator.fit({'train': input_data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "14d841bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.5 ms, sys: 3.68 ms, total: 14.2 ms\n",
      "Wall time: 54.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# importing PyTorchModel\n",
    "\n",
    "container = '763104351884.dkr.ecr.eu-central-1.amazonaws.com/pytorch-inference:1.9.0-gpu-py38-cu111-ubuntu20.04'\n",
    "\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "# Create a model from the trained estimator data\n",
    "# And point to the prediction script\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role=role,\n",
    "                     #image_uri=container,\n",
    "                     framework_version='1.0',\n",
    "                     py_version='py3',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir='source')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "4a4ee6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------*"
     ]
    },
    {
     "ename": "UnexpectedStatusException",
     "evalue": "Error hosting endpoint sagemaker-pytorch-2021-09-22-14-08-23-539: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint..",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m                 Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(self, initial_instance_count, instance_type, serializer, deserializer, accelerator_type, endpoint_name, tags, kms_key, wait, data_capture_config, **kwargs)\u001b[0m\n\u001b[1;32m    731\u001b[0m             \u001b[0mkms_key\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkms_key\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 733\u001b[0;31m             \u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_capture_config_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    734\u001b[0m         )\n\u001b[1;32m    735\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mendpoint_from_production_variants\u001b[0;34m(self, name, production_variants, tags, kms_key, wait, data_capture_config_dict)\u001b[0m\n\u001b[1;32m   3516\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3517\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mconfig_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3518\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexpand_role\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrole\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mcreate_endpoint\u001b[0;34m(self, endpoint_name, config_name, tags, wait)\u001b[0m\n\u001b[1;32m   3019\u001b[0m         )\n\u001b[1;32m   3020\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3021\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendpoint_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3022\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mendpoint_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mwait_for_endpoint\u001b[0;34m(self, endpoint, poll)\u001b[0m\n\u001b[1;32m   3305\u001b[0m                 ),\n\u001b[1;32m   3306\u001b[0m                 \u001b[0mallowed_statuses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"InService\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3307\u001b[0;31m                 \u001b[0mactual_status\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3308\u001b[0m             )\n\u001b[1;32m   3309\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnexpectedStatusException\u001b[0m: Error hosting endpoint sagemaker-pytorch-2021-09-22-14-08-23-539: Failed. Reason:  The primary container for production variant AllTraffic did not pass the ping health check. Please check CloudWatch logs for this endpoint.."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# deploy and create a predictor\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.t2.medium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "bfba13e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code to evaluate the endpoint on test data\n",
    "# returns a variety of model metrics\n",
    "def evaluate(predictor, test_features, test_labels, verbose=True):\n",
    "    \"\"\"\n",
    "    Evaluate a model on a test set given the prediction endpoint.  \n",
    "    Return binary classification metrics.\n",
    "    :param predictor: A prediction endpoint\n",
    "    :param test_features: Test features\n",
    "    :param test_labels: Class labels for test data\n",
    "    :param verbose: If True, prints a table of all performance metrics\n",
    "    :return: A dictionary of performance metrics.\n",
    "    \"\"\"\n",
    "    \n",
    "    # rounding and squeezing array\n",
    "    test_preds = np.squeeze(np.round(predictor.predict(test_features)))\n",
    "    \n",
    "    # calculate true positives, false positives, true negatives, false negatives\n",
    "    tp = np.logical_and(test_labels, test_preds).sum()\n",
    "    fp = np.logical_and(1-test_labels, test_preds).sum()\n",
    "    tn = np.logical_and(1-test_labels, 1-test_preds).sum()\n",
    "    fn = np.logical_and(test_labels, 1-test_preds).sum()\n",
    "    \n",
    "    # calculate binary classification metrics\n",
    "    recall = tp / (tp + fn)\n",
    "    precision = tp / (tp + fp)\n",
    "    accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "    \n",
    "    # print metrics\n",
    "    if verbose:\n",
    "        print(pd.crosstab(test_labels, test_preds, rownames=['actuals'], colnames=['predictions']))\n",
    "        print(\"\\n{:<11} {:.3f}\".format('Recall:', recall))\n",
    "        print(\"{:<11} {:.3f}\".format('Precision:', precision))\n",
    "        print(\"{:<11} {:.3f}\".format('Accuracy:', accuracy))\n",
    "        print()\n",
    "        \n",
    "    return {'TP': tp, 'FP': fp, 'FN': fn, 'TN': tn, \n",
    "            'Precision': precision, 'Recall': recall, 'Accuracy': accuracy}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9f090961",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## TODO: Complete this classifier\n",
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    ## TODO: Define the init function\n",
    "    def __init__(self, input_dim, hidden_1, hidden_2, hidden_3, output_dim):\n",
    "        '''Defines layers of a neural network.\n",
    "           :param input_dim: Number of input features\n",
    "           :param hidden_dim: Size of hidden layer(s)\n",
    "           :param output_dim: Number of outputs\n",
    "         '''\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        # define all layers, here\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
    "        self.fc4 = nn.Linear(hidden_3, output_dim)\n",
    "        # Define dropout\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        # Sigmoid Layer\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    ## TODO: Define the feedforward behavior of the network\n",
    "    def forward(self, x):\n",
    "        '''Feedforward behavior of the net.\n",
    "           :param x: A batch of input features\n",
    "           :return: A single, sigmoid activated value\n",
    "         '''\n",
    "        # your code, here\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.drop(out)\n",
    "        out = self.fc4(out)\n",
    "      \n",
    "        return self.sig(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e23177",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "37cf48e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the training data from a csv file\n",
    "def _get_train_loader(batch_size, data_dir):\n",
    "    print(\"Get train loader.\")\n",
    "\n",
    "    # read in csv file\n",
    "    train_data = pd.read_csv(os.path.join(data_dir, \"train_viewed.csv\"), header=None, names=None)\n",
    "\n",
    "    # labels are first column\n",
    "    train_y = torch.from_numpy(train_data[[0]].values).float()\n",
    "    # features are the rest\n",
    "    train_x = torch.from_numpy(train_data.drop([0], axis=1).values).float()\n",
    "\n",
    "    # create dataset\n",
    "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
    "\n",
    "    return torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
    "\n",
    "# Load the training data from a csv file\n",
    "def _get_validation_loader(batch_size, data_dir):\n",
    "    print(\"Get validation loader.\")\n",
    "\n",
    "    # read in csv file\n",
    "    val_data = pd.read_csv(os.path.join(data_dir, \"validation_viewed.csv\"), header=None, names=None)\n",
    "\n",
    "    # labels are first column\n",
    "    val_y = torch.from_numpy(val_data[[0]].values).float()\n",
    "    # features are the rest\n",
    "    val_x = torch.from_numpy(val_data.drop([0], axis=1).values).float()\n",
    "\n",
    "    # create dataset\n",
    "    val_ds = torch.utils.data.TensorDataset(val_x, val_y)\n",
    "\n",
    "    return torch.utils.data.DataLoader(val_ds, batch_size=batch_size)\n",
    "\n",
    "# Load the training data from a csv file\n",
    "def _get_test_loader(batch_size, data_dir):\n",
    "    print(\"Get test loader.\")\n",
    "\n",
    "    # read in csv file\n",
    "    test_data = pd.read_csv(os.path.join(data_dir, \"test_viewed.csv\"), header=None, names=None)\n",
    "\n",
    "    # labels are first column\n",
    "    test_y = torch.from_numpy(test_data[[0]].values).float()\n",
    "    # features are the rest\n",
    "    test_x = torch.from_numpy(test_data.drop([0], axis=1).values).float()\n",
    "\n",
    "    # create dataset\n",
    "    test_ds = torch.utils.data.TensorDataset(test_x, test_y)\n",
    "\n",
    "    return torch.utils.data.DataLoader(test_ds, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Provided train function\n",
    "def train(model, train_loader, validation_loader, epochs, optimizer, criterion, device):\n",
    "    \"\"\"\n",
    "    This is the training method that is called by the PyTorch training script. The parameters\n",
    "    passed are as follows:\n",
    "    model        - The PyTorch model that we wish to train.\n",
    "    train_loader - The PyTorch DataLoader that should be used during training.\n",
    "    epochs       - The total number of epochs to train for.\n",
    "    optimizer    - The optimizer to use during training.\n",
    "    criterion    - The loss function used for training. \n",
    "    device       - Where the model and data should be loaded (gpu or cpu).\n",
    "    \"\"\"\n",
    "    valid_loss_min = np.Inf # track change in validation loss\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        valid_loss = 0\n",
    "        for batch_idx, (data, target) in enumerate(train_loader, 1):\n",
    "            # prep data\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad() # zero accumulated gradients\n",
    "            # get output of SimpleNet\n",
    "            output = model(data)\n",
    "            # calculate loss and perform backprop\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "            total_loss += loss.item()\n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        model.eval()\n",
    " \n",
    "        for batch_idx, (data, target) in enumerate(validation_loader, 1):\n",
    "            # prep data\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            # get output of SimpleNet\n",
    "            output = model(data)\n",
    "            # calculate loss and perform backprop\n",
    "            loss = criterion(output, target)\n",
    "            # update average validation loss \n",
    "            valid_loss += loss.item()*data.size(0)\n",
    "\n",
    "        # print loss stats\n",
    "        print(\"Epoch: {}, Loss: {}\".format(epoch, total_loss / len(train_loader)))\n",
    "\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, total_loss / len(train_loader), valid_loss / len(validation_loader)))\n",
    "\n",
    "        # save model if validation loss has decreased\n",
    "        if valid_loss <= valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  \\\n",
    "                   Saving model ...'.format(valid_loss_min/len(validation_loader), valid_loss/len(validation_loader)))\n",
    "            torch.save(model.state_dict(), 'model_cifar.pt')\n",
    "            # Set model back to device after saving\n",
    "            model.to(device)\n",
    "            valid_loss_min = valid_loss        \n",
    "        \n",
    "    # save after all epochs\n",
    "    save_model(model, model_dir)\n",
    "\n",
    "\n",
    "# Provided model saving functions\n",
    "def save_model(model, model_dir):\n",
    "    print(\"Saving the model.\")\n",
    "    path = os.path.join(model_dir, 'model.pth')\n",
    "    # save state dictionary\n",
    "    torch.save(model.cpu().state_dict(), path)\n",
    "    \n",
    "def save_model_params(model, model_dir):\n",
    "    model_info_path = os.path.join(args.model_dir, 'model_info.pth')\n",
    "    with open(model_info_path, 'wb') as f:\n",
    "        model_info = {\n",
    "            'input_dim': args.input_dim,\n",
    "            'hidden_1': args.hidden_1,\n",
    "            'hidden_2': args.hidden_2,\n",
    "            'hidden_3': args.hidden_3,\n",
    "            'output_dim': args.output_dim\n",
    "        }\n",
    "        torch.save(model_info, f)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d1de799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get train loader.\n"
     ]
    }
   ],
   "source": [
    "data_dir = 'data'\n",
    "model_dir = 'data'\n",
    "train_loader = _get_train_loader(batch_size=64, data_dir=data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "46e518e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get validation loader.\n"
     ]
    }
   ],
   "source": [
    "validation_loader = _get_validation_loader(batch_size=64, data_dir=data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5516265c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7bf7c34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "## TODO: Complete this classifier\n",
    "class SimpleNet(nn.Module):\n",
    "    \n",
    "    ## TODO: Define the init function\n",
    "    def __init__(self, input_dim, hidden_1, hidden_2, hidden_3, output_dim):\n",
    "        '''Defines layers of a neural network.\n",
    "           :param input_dim: Number of input features\n",
    "           :param hidden_dim: Size of hidden layer(s)\n",
    "           :param output_dim: Number of outputs\n",
    "         '''\n",
    "        super(SimpleNet, self).__init__()\n",
    "        \n",
    "        # define all layers, here\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_1)\n",
    "        self.fc2 = nn.Linear(hidden_1, hidden_2)\n",
    "        self.fc3 = nn.Linear(hidden_2, hidden_3)\n",
    "        self.fc4 = nn.Linear(hidden_3, output_dim)\n",
    "        # Define dropout\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        # Sigmoid Layer\n",
    "        self.sig = nn.Sigmoid()\n",
    "        \n",
    "    \n",
    "    ## TODO: Define the feedforward behavior of the network\n",
    "    def forward(self, x):\n",
    "        '''Feedforward behavior of the net.\n",
    "           :param x: A batch of input features\n",
    "           :return: A single, sigmoid activated value\n",
    "         '''\n",
    "        # your code, here\n",
    "        out = F.relu(self.fc1(x))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc2(out))\n",
    "        out = self.drop(out)\n",
    "        out = F.relu(self.fc3(out))\n",
    "        out = self.drop(out)\n",
    "        out = self.fc4(out)\n",
    "      \n",
    "        return self.sig(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a8a21ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "657ec00b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Loss: 0.6257069819441465\n",
      "Epoch: 1 \tTraining Loss: 0.625707 \tValidation Loss: 37.938244\n",
      "Validation loss decreased (inf --> 37.938244).                     Saving model ...\n",
      "Epoch: 2, Loss: 0.5667100990487036\n",
      "Epoch: 2 \tTraining Loss: 0.566710 \tValidation Loss: 33.929926\n",
      "Validation loss decreased (37.938244 --> 33.929926).                     Saving model ...\n",
      "Epoch: 3, Loss: 0.5360852284409175\n",
      "Epoch: 3 \tTraining Loss: 0.536085 \tValidation Loss: 32.063407\n",
      "Validation loss decreased (33.929926 --> 32.063407).                     Saving model ...\n",
      "Epoch: 4, Loss: 0.5237849187071079\n",
      "Epoch: 4 \tTraining Loss: 0.523785 \tValidation Loss: 31.377724\n",
      "Validation loss decreased (32.063407 --> 31.377724).                     Saving model ...\n",
      "Epoch: 5, Loss: 0.5169930422974524\n",
      "Epoch: 5 \tTraining Loss: 0.516993 \tValidation Loss: 30.698896\n",
      "Validation loss decreased (31.377724 --> 30.698896).                     Saving model ...\n",
      "Epoch: 6, Loss: 0.5155244921969476\n",
      "Epoch: 6 \tTraining Loss: 0.515524 \tValidation Loss: 30.682392\n",
      "Validation loss decreased (30.698896 --> 30.682392).                     Saving model ...\n",
      "Epoch: 7, Loss: 0.5148250770903079\n",
      "Epoch: 7 \tTraining Loss: 0.514825 \tValidation Loss: 30.689847\n",
      "Epoch: 8, Loss: 0.5143993337577748\n",
      "Epoch: 8 \tTraining Loss: 0.514399 \tValidation Loss: 30.675070\n",
      "Validation loss decreased (30.682392 --> 30.675070).                     Saving model ...\n",
      "Epoch: 9, Loss: 0.5116414603228882\n",
      "Epoch: 9 \tTraining Loss: 0.511641 \tValidation Loss: 30.325577\n",
      "Validation loss decreased (30.675070 --> 30.325577).                     Saving model ...\n",
      "Epoch: 10, Loss: 0.5128166237724162\n",
      "Epoch: 10 \tTraining Loss: 0.512817 \tValidation Loss: 30.158344\n",
      "Validation loss decreased (30.325577 --> 30.158344).                     Saving model ...\n",
      "Epoch: 11, Loss: 0.5104833614603381\n",
      "Epoch: 11 \tTraining Loss: 0.510483 \tValidation Loss: 30.175795\n",
      "Epoch: 12, Loss: 0.5115250099485166\n",
      "Epoch: 12 \tTraining Loss: 0.511525 \tValidation Loss: 30.267168\n",
      "Epoch: 13, Loss: 0.512863926241331\n",
      "Epoch: 13 \tTraining Loss: 0.512864 \tValidation Loss: 30.375442\n",
      "Epoch: 14, Loss: 0.5126496103879448\n",
      "Epoch: 14 \tTraining Loss: 0.512650 \tValidation Loss: 30.318952\n",
      "Epoch: 15, Loss: 0.5122297827328477\n",
      "Epoch: 15 \tTraining Loss: 0.512230 \tValidation Loss: 30.229060\n",
      "Epoch: 16, Loss: 0.5108107683257522\n",
      "Epoch: 16 \tTraining Loss: 0.510811 \tValidation Loss: 30.380035\n",
      "Epoch: 17, Loss: 0.5138116988066201\n",
      "Epoch: 17 \tTraining Loss: 0.513812 \tValidation Loss: 30.137345\n",
      "Validation loss decreased (30.158344 --> 30.137345).                     Saving model ...\n",
      "Epoch: 18, Loss: 0.5122792928018303\n",
      "Epoch: 18 \tTraining Loss: 0.512279 \tValidation Loss: 30.276701\n",
      "Epoch: 19, Loss: 0.5155514396796717\n",
      "Epoch: 19 \tTraining Loss: 0.515551 \tValidation Loss: 30.321711\n",
      "Epoch: 20, Loss: 0.5125142928595855\n",
      "Epoch: 20 \tTraining Loss: 0.512514 \tValidation Loss: 30.178564\n",
      "Saving the model.\n",
      "CPU times: user 27.5 s, sys: 257 ms, total: 27.8 s\n",
      "Wall time: 27.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#def train(model, train_loader, validation_loader, epochs, optimizer, criterion, device):\n",
    "\n",
    "model = SimpleNet(input_dim, hidden_1, hidden_2, hidden_3, output_dim)\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "## TODO: Define an optimizer and loss function for training\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "\n",
    "\n",
    "train(model, train_loader, validation_loader, 20, optimizer, criterion, device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d9fc87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "f48f691e",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2dfd41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get test loader.\n"
     ]
    }
   ],
   "source": [
    "test_loader = _get_test_loader(batch_size=64, data_dir=data_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0e5af9f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>0.2530120481927711</th>\n",
       "      <th>0.33333333333333337</th>\n",
       "      <th>0</th>\n",
       "      <th>1.1</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.2</th>\n",
       "      <th>1.0</th>\n",
       "      <th>1.0.1</th>\n",
       "      <th>1.0.2</th>\n",
       "      <th>0.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.438476</td>\n",
       "      <td>0.393389</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.677778</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.433735</td>\n",
       "      <td>0.655556</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.011111</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25166</th>\n",
       "      <td>1</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25167</th>\n",
       "      <td>1</td>\n",
       "      <td>0.469880</td>\n",
       "      <td>0.388889</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25168</th>\n",
       "      <td>1</td>\n",
       "      <td>0.349398</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25169</th>\n",
       "      <td>0</td>\n",
       "      <td>0.710843</td>\n",
       "      <td>0.811111</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25170</th>\n",
       "      <td>1</td>\n",
       "      <td>0.397590</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>25171 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       1  0.2530120481927711  0.33333333333333337  0  1.1  0.1  0.2  1.0  \\\n",
       "0      1            0.438476             0.393389  0    0    0    1  1.0   \n",
       "1      1            0.438476             0.393389  0    0    0    1  1.0   \n",
       "2      1            0.349398             0.677778  1    0    0    0  1.0   \n",
       "3      0            0.433735             0.655556  0    1    0    0  1.0   \n",
       "4      1            0.686747             0.011111  0    1    0    0  1.0   \n",
       "...   ..                 ...                  ... ..  ...  ...  ...  ...   \n",
       "25166  1            0.746988             0.500000  1    0    0    0  1.0   \n",
       "25167  1            0.469880             0.388889  1    0    0    0  1.0   \n",
       "25168  1            0.349398             0.400000  0    1    0    0  1.0   \n",
       "25169  0            0.710843             0.811111  1    0    0    0  1.0   \n",
       "25170  1            0.397590             0.766667  1    0    0    0  1.0   \n",
       "\n",
       "       1.0.1  1.0.2  0.0  \n",
       "0        1.0    1.0  1.0  \n",
       "1        1.0    0.0  1.0  \n",
       "2        1.0    1.0  1.0  \n",
       "3        1.0    1.0  0.0  \n",
       "4        1.0    1.0  0.0  \n",
       "...      ...    ...  ...  \n",
       "25166    1.0    1.0  1.0  \n",
       "25167    1.0    1.0  1.0  \n",
       "25168    1.0    1.0  1.0  \n",
       "25169    1.0    1.0  0.0  \n",
       "25170    1.0    1.0  1.0  \n",
       "\n",
       "[25171 rows x 11 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv('data/test_viewed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "58b38045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.473\n",
      "Test accuracy: 0.765\n"
     ]
    }
   ],
   "source": [
    "# Get test data loss and accuracy\n",
    "\n",
    "test_losses = [] # track loss\n",
    "num_correct = 0\n",
    "\n",
    "# init hidden state\n",
    "#h = net.init_hidden(batch_size)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "\n",
    "for data, targets in test_loader:\n",
    "\n",
    "    # get output of SimpleNet\n",
    "    output = model(data)\n",
    "    # calculate loss and perform backprop\n",
    "    test_loss = criterion(output, targets)\n",
    "\n",
    "    test_losses.append(test_loss.item())\n",
    "\n",
    "    # convert output probabilities to predicted class (0 or 1)\n",
    "    pred = torch.round(output.squeeze())  # rounds to the nearest integer\n",
    "\n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(targets.float().view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy())\n",
    "    num_correct += np.sum(correct)\n",
    "\n",
    "\n",
    "# -- stats! -- ##\n",
    "# avg test loss\n",
    "print(\"Test loss: {:.3f}\".format(np.mean(test_losses)))\n",
    "\n",
    "# accuracy over all test data\n",
    "test_acc = num_correct/len(test_loader.dataset)\n",
    "print(\"Test accuracy: {:.3f}\".format(test_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8d4d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
